scipy and numpy=Eli Bressert;Note=Erxin

# introduction
- use cython to communicate c code with python code
- well know comprehensive precompiled python packages
    + Enthought Python Distribution(EPD)
    + Active Python
- install python    
    + macports
    sudo port install py27-numpy py27-scipy py27-ipython
    + fedora
    sudo yum install numpy scipy
    
# Numpy 
- numpy arrays
n-dimensional arrays, element by element operations, only support save same type elements
- element types
floats, integers, strings
- simple example
import numpy as np
arr = np.arange(1e7)
larr = arr.tolist()
- numpy array loop is faster than normal python code
- timeit could caculate a function's execute time
- numpy.matrix only support two dimensional data
- array creation and datat typing
    + np.array(iterable_type)
    + np.zero, np.arange, np.linespace, np.logspace, np.zeros, np.ones
    + specify datatype
    np.array(2, dtype=int)
- change array's dimension
ary.reshape(tupe_of_shape)
ary.reshape((2,3,4))
- flatten n-dimension array to one dimension
aryNd.ravel()
- record arrays, complex data save in numpy array in recarray, it's like normal table conception, come column may contain string others may contain numeric
    + example to create recarray
    recarr = np.zeros((2,), dtype=('i4, f4, a10'))
    toadd = [(1,2.,'hello'), (2,3.,'world)]
    recarr = toadd
    dtype optional argument is defining the types designed for the first to third columns where i4 correspond to a 32-bit integer, f4 corresponds to a 32-bit float, a10 correspond to a string 10 characters
    + use zip to populate the recarray
    recarr = np.zeros((2,), dtype=('i4, f4, a10'))
    col1 = np.arange(2) + 1
    col2 = np.arange(2, dtypes=np.float32)
    col3 = ['hello', 'world']
    toadd = zip(col1, col2, col3)
    recarr[:] = toadd
    recarr.dtypes.names = ('id', 'price', 'name') # add column names
    recarr('id') # access the column by column name
- indexing and slicing
nparray[index0, index1, index2, ...] #indexing
    + create index array by condition example
    indexes = np.where(np_array > expression)
    np.delete(np_array, indexes)
    + using boolean expression
    indexes = np_array > condition
    np_array[indexes]
    + the first one is faster, the second is readable
    + slicing
    np_array[start:end, start:end]
- boolean statements and numpy arrays
    + np_array could execute boolean operation to single value
    + np_array could only do & and | operation on np_array
- clone array
new_ary = np.copy(np_array)
- all the python's normal operation could be done to the numpy array
- text file
    + np.loadtxt function will work very well as long as all the data is of a simple type
    + np.savetxt function to save data into text file
    + to save the recarray, need to specify the data type
    table = np.loadtxt('data.txt',
                        datatype='names':('ID', 'Result', 'Type'),
                        'formats':('S4', 'f4', 'i2'))
    + another way to save recarray data type tool is matplotlib.mlab tool
    + np.savez, is a another alternative version 
- math
    + python have it's own math module, but the match module such as math.cos will not work with numpy
    + numpy have it's own math module
    + linear algebra, such as numpy.dot, numpy.transpose
    example calculate the expression
    3x+6y−5z=12
    x−3y+2z=−2
    5x−y+4z=10
    solve the equations by matrix
    
    import numpy as np
    A = np.matrix([[3, 6, -5],
                   [1, -3, 2],
                   [5, -1, 4]])
    B = np.matrix([[12],
                   [-2],
                   [10]])
    X = A ** (-1) * B
    print(X)
    + numpy operation
    np.linalg.inv(), invert a matrix
    np.matrix_obj.dot(matrix_obj)
    
# Scipy
- introduction, it's a package that utilizes numpy arrays and manipulations to take on standard problems that scientists and engineers commonly face
- common tasks
interpolation, integration, spatial analysis, clustering, signal and image processing, sparse matrices and statistics
- numpy and scipy provide optimization and minimization tools but don't contain Markov Chain Monte Carlo(MCMC) capabilities, there are several popular MCMC python packages like PyMC
- data modeling and fitting
- curve_fit, X^2 based method
import numpy as np
from scipy.optimize import curve_fit
- creating a function to model and create data
def func(x, a, b):
    return a * x + b
x = np.linspace(0, 10, 100)
y = func(x, 1, 2)
yn = y + 0.9 * np.random.normal(size=len(x))

popt, pcov = curve_fit(func, x, yn)
print(popt)
- solutions to functions, use scipy.optimize.fsolve
from scipy.optimize import fsolve
import numpy as np
line = lambda x: x + 3
solution = fsolve(line, -2)
print(solution)
use fsolve could do intersection between two functions
- interpolation, there are two basic methods of interpolation
    + fit one function to an entire dataset
    + fit different parts of the dataset with several functions
    + module in scipy
    from scipy.interpolate import interp1d
    import numpy as np
    x = np.linspace(0, 10*np.pi, 20)
    y = np.cos(x)
    
    f1= interp1d(x, y, kind='linear')
    fq= interp1d(x, y, kind='quadratic')
    
    xint = np.linspace(x.min(), x.max(), 1000)
    yintl = f1(xint)
    yintq = fq(xint)
    
- use spline-fitting we could interpolate noisy data
- interpolation could also used as filter functions
    + example
    import numpy as np
    from scipy.interpolate import griddata
    # Defining a function
    ripple = lambda x, y: np.sqrt(x**2 + y**2)+np.sin(x**2 + y**2)
    # Generating gridded data. The complex number defines
    # how many steps the grid data should have. Without the
    # complex number mgrid would only create a grid data structure
    # with 5 steps.
    grid_x, grid_y = np.mgrid[0:5:1000j, 0:5:1000j]
    # Generating sample that interpolation function will see
    xy = np.random.rand(1000, 2)
    sample = ripple(xy[:,0]*5,xy[:,1] * 5)
    # Interpolating data with a cubic
    grid_z0 = griddata(xy * 5, sample, (grid_x, grid_y), method='cubic')
    + griddata is more robust than the SmoothBivariateSpline
    
- integration, SimPy package which solve mathematical problems symbolically for many types of computation beyond calculus
    + example
    import numpy as np
    from scipy.integrate import quad
    # Defining function to integrate
    func = lambda x: np.cos(np.exp(x)) ** 2
    # Integrating function with upper and lower
    # limits of 0 and 3, respectively
    solution = quad(func, 0, 3)
    print solution
    # The first element is the desired value
    # and the second is the error.
    # (1.296467785724373, 1.397797186265988e-09)
    + numerical integration
    import numpy as np
    from scipy.integrate import quad, trapz
    # Setting up fake data
    x = np.sort(np.random.randn(150)*4+4).clip(0,5)
    func = lambda x: np.sin(x) * np.cos(x ** 2) + 1
    y = func(x)
    # Integrating function with upper and lower
    # limits of 0 and 5, respectively
    fsolution = quad(func, 0, 5)
    dsolution = trapz(y, x=x)
    
- statistics, there are basic statistic function in numpy array, like mean, std, median, argmax and argmin
    + scipy.stats package provides
    + we call a distribution from scipy.stats and extra info in several ways
        * probability density functions (PDFs)
        PDF = e ^ ((-x^2/2)/(2*pi)^0.5)
        * cumulative distribution functions, (CDFs)
        * random variable sample (RVFs)
        * percent point functions, (PPFs)
    + demonstrate how to access the distribution
    import scipy.stats import norm
    import numpy as np
    x = np.linspace(-5, 5, 1000)
    dist = norm(loc=0, scale=1)
    pdf = dist.pdf(x)
    cdf = dist.cdf(x)
    sample = dist.rvs(500)
    + functions, there are more than 60 statistical functions, such as kstest and normaltest 
    from scipy import stats
    stats.kstest
    
- spatial and clustering analysis, spatial and clustering analysis are key to identifying patterns, groups, and clusters. 
    + package provide good graph theory capabilities, NetworkX, excellent for create python modulating and study the structure of complex networks
    + scipy provide a spatial analysis class, scipy.spatial
    vector quantization groups and hierarchical clustering groups
    + cluster analysis class, scipy.cluster
    + Hierarchical clustering is a powerful tool for identifying structures that are nested within larger structures.
    + example
    import numpy as np
    from scipy.cluster import vq
    # Creating data
    c1 = np.random.randn(100, 2) + 5
    c2 = np.random.randn(30, 2) - 5
    c3 = np.random.randn(50, 2)
    # Pooling all the data into one 180 x 2 array
    data = np.vstack([c1, c2, c3])
    # Calculating the cluster centroids and variance
    # from kmeans
    centroids, variance = vq.kmeans(data, 3)
    # The identified variable contains the information
    # we need to separate the points in clusters
    # based on the vq function.
    identified, distance = vq.vq(data, centroids)
    # Retrieving coordinates for points in each vq
    # identified core
    vqc1 = data[identified == 0]
    vqc2 = data[identified == 1]
    vqc3 = data[identified == 2]
    
- Signal and Image Processing, provide process jpeg and png images
    + example
    import numpy as np
    from scipy.misc import imread, imsave
    from glob import glob
    # Getting the list of files in the directory
    files = glob('space/*.JPG')
    # Opening up the first image for loop
    im1 = imread(files[0]).astype(np.float32)
    # Starting loop and continue co-adding new images
    for i in xrange(1, len(files)):
    print i
    im1 += imread(files[i]).astype(np.float32)
    # Saving img
    imsave('stacked_image.jpg', im1)
    
    The JPG images in the Python environment are NumPy arrays with(426, 640, 3), where the three layers are red, green, and blue, respectively
    
- Sparse matrices, fit for 10^10 elements in matrix with many zero elements
    + example
    import numpy as np
    from scipy.sparse.linalg import eigsh
    from scipy.linalg import eigh
    import scipy.sparse
    import time
    N = 3000
    # Creating a random sparse matrix
    m = scipy.sparse.rand(N, N)
    # Creating an array clone of it
    a = m.toarray()
    print('The numpy array data size: ' + str(a.nbytes) + ' bytes')
    print('The sparse matrix data size: ' + str(m.data.nbytes) + ' bytes')
    # Non-sparse
    t0 = time.time()
    
- reading and writing file beyond numpy
    + support ascii
    + support binary fit for python environment read write
    + support matlab files, scipy.io.loadmat, scipy.io.savemat
    + support read astronomy, geography, medicine, there is a programming language called IDL, the save file could be read from scipy from scipy.io.readsav
    + support query matrix market files, also support sparse matrix, which are written in ascii format, well support by other kinds of language C, fortran, matlab
    
# SciKit, taking scipy one step further
- There are currently more than 20 scikit packages available; a list can be found athttp://scikit.appspot.com/. 
- it's a tool kit package for sci
- scikit-image, These advanced and high-level modules include color space conversion, image intensity adjustment algorithms, feature detections, filters for sharpening and denoising, read/write capabilities
- scikit-learn, It is an easy-to-use machine learning bundle that contains a collection of tools associated with supervised and unsupervised learning





    

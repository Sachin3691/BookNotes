LRC, LRE, LRP architecture;Note=Erxin

# LRC
- Test run environment will be destroy in each test run 

{Test Run environment
    {AWS LRC control panel

        kafka
        
        shceduler 
        
        results aggregators 
        
        results reporter 
        
        TDigest aggregators 
        
        Cloud tunnel 
        
        Analytics 
        
        DB 
        
        TDigest reporter 
    }

    {LRC cloud load environment 

        AWS/Azure 

        SiteScope 
        WPT

        CSB
    }

    {Customer load environment (on-premise)}
    {Customer AUT}
}
^
|
V
{Microfocus Saas AWS
    {monitor grafana 
    mail server }

    {access VPC 

    }

    {LRC (App) VPC
        {Mng
            logstash 
            promethus 
            admin tomcat 
            operation console 
            kubernetes master
        }
        
        {Application
            tomcat 
            app servers 
            open API 
            offline reporter 
            hub 
            task scheduler 
            TDigest servers 
        }
        {Infra 
            RabbitMq
        
        }
    }
    {Transit VPC
    }
} 
 
- update data in each 5 seconds 
- we will save the database into AWS data bucket and let the sass AWS get and agresgate the result into the main database 

- the main server connect the spown test environment with client certificate 

- TDigest, is algorithm to take and save the raw test data and allow querying the result 

it is offline result to provide more accurate reports 

t-digest, a third party data structure 

elastic-search also use this data structure 

- on-promise using websockets communicate between cloud tunnel and customer load environment 

- any webserver have server certificates 

- other issues 

customer firewalls 
different environments 
how many IPs required to provide the required loads 

shared analysis 

- data flows 
- the test tendense will be rebuild for each customers to prevent security issues 

- support machine pools 


# LRP
- nearly 30 years, come from the company mercury, bought by HP, shift to microfocus 

- shared components 
{LRP

    {LRE
    }

    {LRC
    }

    {LRD
    }
    
    controller 
    oneLG 
    protocols 
    analysis
    vugen 
    MDRV 
}

- wpf, vugen 

*.lrp 

extends, LR/dat/protocols/*.lrp 
 
the protocol will be displayed in the vugen create new script dialog 

- correlation in web http 

    + dynamic generated form fields and the client should send the values back to serer for authentications etc. 
    
- recording, windows hook will record. replace lr dll to system dlls 

    + the script will be generated 

    + design studio to do the correlation 
    
    it will use some rules to scan and replace values 
    
    curly braces {
    
- controller 

    + pick the recorded scripts 
    + load runner APIs in different languages such as .net, java etc. customer can use their own IDE to design the scripts 
    
    customer can create their own unit tests 
    
    + support jmeter and galting scripts 
    
    + will support selenium and silk peroformer 
    
    + run mode 
    real-world schedule, configure details in stages, very flexible 
    
    basic schedule, allow simple logic 

    + configure the load generates 
    
    windows lg
    linux lg 
    
    build TCP/IP connections, typical is TCP, it is HTTP mode, need the connection keep alives 
    
    you can create multiple kinds of network profiles to set the connect IPs, proxy etc. 
    
    using the MI listener 

    + x64 process? refactor from 32 to 64 
    
    + max vusers 2.5k? decide by the hardware , 5k?

- analysis 

    + partial results, linux lg or windows failed to collect results 
    
    + analysis how options to compare the results, the user manage them 
    
    + we can also manually copy the results for analysis 
    
    + double click the res file in the result folder to open the analysis 
    
    + during the test the data is send with summary data 
    
    after test run the whole data is collected in LRE 
    
    + filter merge, group by, compare etc. allow all the statistic way to filter the data 
    
    



















































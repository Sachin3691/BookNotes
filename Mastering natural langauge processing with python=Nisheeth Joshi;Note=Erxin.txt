Mastering natural langauge processing with python=Nisheeth Joshi;Note=Erxin

# Applying similarity measures using Ethe edit distance algorithm 
- Edit distance or the Levenshtein edit distance between two strings is used to compute the number of characters that can be inserted, substitued, or deleted in order to make two things strings equal

- Jaccard's coeffienct, or Tanimoto coefficient may be defined as a measure of the overlap of two sets X and Y

it may be defined as follows 
    + Jaccard(X, Y) = |X and Y|/X or Y|
    + Jaccard(X, X) = 1
    + Jaccard(X, Y) = 0 if X and Y = 0 

- The smith Waterman distance is similar to edit distance. This similarity metric was developed in order to detect the optical alignments between related protein sequences and DNA. It consists of costs to be assigned 

- Maximum Entropy Model in NLTK
- Unigram represents a single token. The following code will be used for generated unigrams for Alpino Corpus

- The preceding code we can add a word filter that can be used to eliminate stopwords and punctuation 

- The Maximum likelihood estimation(MLE) model interpolation on data and so on
- distribution in Markov Chain Monte Carlo (MCMC). one way is using the metropolis-hastings sample 


# Morphological generator 
- perform morphological analysis and generation are as follows: Morph is a morphological generator and analyzer for English for the RASP system Morphy is a morphological generator, analyzer, and POS tagger for German Morphisto is a morphlogical generator and analyzer for GermanMorfette performs supervised learning 


# Parts of speech tagging identifying words 
- taggers can be used to form a back off chain so that the next tagger can be used for tagging if one tagger is not tagging. Let's see the list of available tags provided by Penn Treebank 
- Parts of speech(POS) tagging is one of the many tasks in NLP. It is defined as the process of assigning a particular parts of speech tag identifies whether a word is a noun, verb, adjective and so on 
- In this chapter, we have discussed semantic analysis which is also one of the phase of natural language processing. we have discussed NER, NER using hMM, NER using Machine learning toolkits performance metrics of NER, NER using POS tagging and WSD using Wordnet and the Genration of Synsets 


# Sentiment Analysis I am happy 
- one example of the word list is affective norms for English words (ANEW)
- The summarization is the process of generating summaries from a given long text. based on the Luhn work. The automatic creation of Literature Abstracts
























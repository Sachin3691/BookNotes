Node in Practice=Alex Young;Note=Erxin

# Node fundamentals 
- getting started 
    + microsoft developed webmatrix which directly support node 
    
    + node web framework, http://expressjs.com 
    
    + when to use node 
    advertising distribution 
    game server 
    content management system, blog 
    
    + main festures 
    app.js 
    core module 
    c++ buildings 
    libuv, c-ares, http  | v8 
    os 
    
    every node developers runs into EventEmitter, it's the actually the basis for most of node's core modules 
    
    + stream, the basis for scalable i/o, using node's stream api allows you to create an object that receives events about the connection 
    
    + get information about files with fs.stat and synchronous equivalent is fs.statSync 
    
    use fs.createReadSream to return a ReadableStream 
    
- building a node application 
- creating a new node project file.js 
    + create a new directory, cd into it and then run npm init
    $ npm init 
    
    + making a stream class 
    var writable = require('stream').writable;
    var util = require('util');
    
    module.exports = CountSteam;
    
    util.inherits(CountStream, writable);
    
    function CountSteam(matchText, options){
        writable.call(this, options);
        this.count = 0; 
        this.matcher = new RegExp(matchText, 'ig'); //create a regexp object 
    }
    
    CountStream.prototype._write = function (chunk, encoding, cb){
        var matches = chunk.toString().match(this.matcher);
        if(matches){
            this.count += matches.length;
        }
        cb();
    }
    
    CountSteam.prototype.end = function(){
        this.emit('total', this.count);
    };
    
    // using the stream 
    var CountStream = require('./countstream');
    var countStream = new CountStream('book');
    var http = require('http');
    http.get('http://www.manning.com', function(res) {
    res.pipe(countStream);
    });
    countStream.on('total', function(count) {
    console.log('Total matches:', count);
    });
    
    + writing a test 
    var assert = require('assert');
    
    update the test property of package.josn to 
    "scripts":{
        "test": "node test.js"
    },

- globals node's environment 
    + global process object 
    + node's Buffer class 
    + globals, in module scope 
    
    + modules, can be used to organize larger programs and distribute, load module use require 
    
    $ npm search express 
    
    $ npm install express 
    
    var express = requre('express');
    
    global module 
    /sur/local/lib/node_modules on *nix 
    
    npmsearch command which created by Gorgi Kosev will order results using its own relevance rankings 
    
    + creating and managing modules 
    use the exports object, node have a built-in module system base on CommonJS Modules/1.1 
    http://wiki.commonjs.org/wiki/Modules/1.1/
    
    function MyClass(){
    
    }
    
    MyClass.prototype = {
        method: function(){
            return 'Hello';
        }
    };
    
    var myClass = new MyClass();
    module.exports = myClass;
    exports.method = function(){
    };
    
    node will attempt to find a module in $NODE_PATH then ./node_modules $HOME/.node_modules 
    
    + unloading modules from require.cache object 
    delete require.cache[require.resolve('loaded-module-path')];
    
    + loading a group of related modules 
    
    ndoe's module system supports by allowing directories to act as modules. the easiest way to do this is to create a file cached index.js that has a require statement to load each file. 
    module.exports = {
        one: require('./one');
        two: require('./two');
    };
    
    if no package.json is present, it'll then look for index.js 
    
    working with paths, solution use __dirname or __filename to determine the location of the file 
    
    + standard i/o and the console object 
    
    + reading and writing to standard i/o 
    process.stdout 
    process.stdin 
    process.stdin.resume(); //tell the stream we're ready to start reading 
    process.stdin.setEncoding('utf8');
    
    process.stdin.on('data', function(id){
        process.stdout.write(d);
    });
    
    + logging message 
    console.log, console.info, console.error and console.warn 
    
    format placeholders 
    %s, string 
    %d, number
    %j, json 
    
    + benchmarking a program 
    console.time(), console.timeEnd() 
    
    var stream = require('fs').createReadStream(file);
    
    stream.on('end', function(){
        console.timeEnd('read');
    });
    
    third party benchmark module, https://npmjs.org/package/benchmark, microtime 
    
    + operating system and command-line integration 
    process.arch and process.platform 
    'x64', 'ia32', ... 
    
    the process's current memory usuage 
    rss, resident set size 
    heapTotal 
    heapUsed 
    
    + passing commandline arguments 
    process.argv 
    
    node argument.js -r arguments.js 
    
    + exit program 
    process.exit()
    
    + script use mongoose database library, http://mongoosejs.com need to call mongoose.connection.close() before process will be able to exit 
    
    + you need to response to signals sent by other process, use the signal events that send to the process object 
    
    add a POSIX signal name should work for unix system, type man sigaction to see the names of all of the signals 
    process.stdin.resume(); //read from stdin so the program will run until ctrl-c is pressed or it's kill 
    process.on('SIGHUP', function() {
        console.log('reloading configuration');
    });
    
    process.kill(pid, [signal]);
    
    + delaying execution with timers 
    
    setTimeout 
    
    setInterval 
    
    + managing asynchronous api 
    var EventEmitter = require('events').EventEmitter;
    
    process.nextTick to wrap the synchronous operations 
    process.nextTick(function(){
        events.emit('success');
    });
    
    setImmediate and clearImmediate global functions accept a callback and optional arguments and will run after any upcoming i/o events but before setTimeout and setInterval
    
    callbacks added this way are pushed onto a queue and one callback will be executed per run loop this is different from process.nextTick, which causes process.maxTickDepth callbacks to run 
    
    process.nextTick is usually run at the end to current event loop 
    
    
- buffers 
    + buffers are raw allocations of the heap, exposed to javascript in an array-like manner 
    + changing data encoding 
    Buffer.isBuffer(bf);
    
    var fs = require('fs');
    fs.readFile('./file.txt', function(err, buf){
        console.log(buf.toString());
    });
    
    + changing string encoding using buffers 
    
    var buf = new Buffer('string', 'encoding-type');
    
    + converting binary files to json, DBase 5.0 header specification *.dbf file 
    
    var date = new Date();
    date.setUTCFullYear(1900 + buf[1]);
    date.setUTCMonth(buf[2]);
    date.setUTCDate(buf[3]);
    header.lastUpdated = date.toUTCString();
    
    buf.readUInt8()

- events 
    + basic usage, the base class must be inherit from EventEmitter
    var util = require('util');
    var events = require('events');
    function MusicPlayer() {
    events.EventEmitter.call(this);
    }
    util.inherits(MusicPlayer, events.EventEmitter);
    
    var musicPlayer = new MusicPlayer();
    musicPlayer.on('play', function(track) {
    this.playing = true;
    AudioDevice.play(track);
    });
    musicPlayer.on('stop', function() {
    this.playing = false;
    AudioDevice.stop();
    });
    musicPlayer.emit('play', 'The Roots - The Fire');
    setTimeout(function() {
    musicPlayer.emit('stop');
    }, 1000);
    
    the util.inerits is the easiest and most common way to create customized event-based classes 
    
    //removing listeners 
    function play(track){
        this.playing = true;
    }
    musicPlayer.removeListener('play', play);
    
    musticPlayer.once('play', {
        this.audioFirstStarted = new Date();
    });
    
    + EventEmitter methods, on, emit and removeListener
    
    + mixing in EventEmitter
    var EventEmitter = reuquire('events').EventEmitter;
    
    + error handling 
    source.on('error', function(err){
    });
    
    source.emit('error', options);
    
    an error event are treated as a special case in Node, the default action is print a stack and exit the program 
    
    + managing errors with domains, node's domain API provides a way of wrapping existing non-blocking APIs and exceptions with error handlers. this helps centralize error handling and is particularly useful
    
    var util = require('util');
    var domain = require('domain');
    var events = require('events');
    var audioDomain = domain.create();
    
    function AudioDevice() {
        events.EventEmitter.call(this);
        this.on('play', this.play.bind(this));
    }
    util.inherits(AudioDevice, events.EventEmitter);
    
    AudioDevice.prototype.play = function() {
        this.emit('error', 'not implemented yet');
    };
    
    function MusicPlayer() {
        events.EventEmitter.call(this);
        this.audioDevice = new AudioDevice();
        this.on('play', this.play.bind(this));
        this.emit('error', 'No audio tracks are available');
    }
    util.inherits(MusicPlayer, events.EventEmitter);
    
    MusicPlayer.prototype.play = function() {
        this.audioDevice.emit('play');
        console.log('Now playing');
    };
    
    audioDomain.on('error', function(err) {
        console.log('audioDomain error:', err);
    });
    
    audioDomain.run(function() {
        var musicPlayer = new MusicPlayer();
        musicPlayer.play();
    });
    
    + advanced patterns, reflection, for dynamic respond to changes to an instance of an EventEmitter
    
    track when listeners are added, emit a new-listener event 
    var util = require('util');
    var events = require('events');
    function EventTracker() {
    events.EventEmitter.call(this);
    }
    util.inherits(EventTracker, events.EventEmitter);
    var eventTracker = new EventTracker();
    eventTracker.on('newListener', function(name, listener) {
    console.log('Event name added:', name);
    });
    eventTracker.on('a listener', function() {
    // This will cause 'newListener' to fire
    });
    
    + use rabbitmq with node
    + use zeromq with node 
    
- streams 
    + introduce to streams, in node streams are an abstract interface adhered to by several different objects. it means a way of doing things 
    
    streams can be read, write and implemented with EventEmitter, it provide creating data flows between objects. can be composed LEGO-like modularity 
    
    + types of streams, stream handbook https://github.com/substack/stream-handbook/
    built-in, such as fs.createReadSream
    http 
    parsers, such as xml or json 
    browser, node's event-based streams have been extended to work in browsers 
    audio 
    RPC
    test 
    control, meta and state 
    
    + when to use streams, stream is asynchronous by design, rather than reading entire file into memory a buffer's worth will be read, the desired operations will be performed and then result will be written to the output stream 
    
    node is like unix pipes 
    
    + streams in thrid party modules, streams2 
    stream.Readable, _read(size)
    stream.Writable, _write(chunk, encoding, callback)
    stream.Duplex, _read(size), _write(chunk, encoding, callback)  a readable and writable stream like a network connection 
    stream.Transform, _flush(size), _transform(chunk, encoding, callback), a duplex stream that changes data in some way 
    
    the Mongoose MongoDB module, http://mongoosejs.com 
     
    the pipe and unpipe events are emitted when passing a stream to the stream.Readable.prototype.pipe method 
    
    + built-in streams 
    
        * send a file from a web server to a client in an effcient manner 
        fs.createReadStream to open a file and sream it to the client 
        
        var http = require('http');
        var fs = require('fs');
        
        http.createServer(function(req, res){
            fs.readFile(__dirname + '/index.html', function(err, data){
                if (err){
                    res.statusCode = 500;
                    res.end(String(err));
                }
                else{
                    res.end(data);
                }
            });
        }).listen(8000);
     
    replace the above code with fs.createReadStream will significate improve the performance 

    + demonstrates a streaming static web server 
    var http = require('http');
    var fs = require('fs');
    http.createServer(function(req, res) {
        fs.createReadStream(__dirname + '/index.html').pipe(res);
    }).listen(8000);
     
    use gzip to response 
     
     var http = require('http');
     var fs = require('fs');
     var zlib = require('zlib');
     http.createServer(function (req, res) {
     	res.writeHead(200, {
     		'content-encoding' : 'gzip'
     	});
     	fs.createReadStream(__dirname + '/index.html')
     	.pipe(zlib.createGzip())
     	.pipe(res);
     }).listen(8000);
     
    general pattern is readable.pipe(writable);
     
    + handle error, add error listener 
    var fs = require('fs');
    var stream = fs.createReadStream('not-found');
    stream.on('error', function (err) {
    	console.trace();
    	console.error('Stack:', err.stack);
    	console.error('The error raised was:', err);
    });
     
    console.trace() will show a trace up to the ReadStream implementation in Node’s events.js core module.
     
    + third party modules and streams, the express web framework, http://expressjs.com/ it provides a relatively lightweight wrapper around node's core http module 
    
    it includes the Request and Response objects 
    
    Express route a callback that runs for a given http method and url, uses res.send to respond with some data 
    
    var express = require('express');
    var app = express();
    app.get('/', function (req, res) {
    	res.send('hello world');
    });
    app.listen(3000);
     
    req, is a Request object 
    res, is a Response object 
    
    //Express 3 and streams content from a custom readable stream by using pipes 
    var stream = require('stream');
    var util = require('util');
    var express = require('express');
    var app = express();
    util.inherits(StatStream, stream.Readable);
    function StatStream(limit) {
    	stream.Readable.call(this);
    	this.limit = limit;
    }
    StatStream.prototype._read = function (size) {
    	if (this.limit === 0) {
    		// Done
    		this.push();
    	} else {
    		this.push(util.inspect(process.memoryUsage()));
    		this.push('n');
    		this.limit--;
    	}
    };
    app.get('/', function (req, res) {
    	var statStream = new StatStream(10);
    	statStream.pipe(res);
    });
    app.listen(3000);
     
    + use stream with mongoosejs 
    User
        .where('role')
        .equals('admin')
        .stream()
        .pipe(writeStream);
     
    + use stream with mysql 
    var query = connection.query('SELECT * FROM posts');
    query
    .on('result', function (row) {
    	connection.pause();
    	processRow(row, function () {
    		connection.resume();
    	});
    });
     
    + using the strem base classes, provide templates for solving the kinds of problems that streams are best at stream.Transform is great for parsing data and stream.Readable is perfect for wrapping lower-level apis 
    
    + correctly inheriting from the stream base classes, not sure which base classes to use and how to use it 
    
    then use Object.prototype.call and util.inherites 
    
    the base class are abstract class need to implement method
    
    five basic class Readable, Writable, Duplex, Transform and PassThrough 
    
    Transform is used when change data in some way by parsing it 
    PassThrough is used when extract data from streams without changing it from testing to analysis 
    
    inherit from the base class
    MyStream.prototype = new Stream.Readable() 
    
    var Readable = require('stream').Readable;
    function MyStream(options) {
    	Readable.call(this, options);
    }
    MyStream.prototype = Object.create(Readable.prototype, {
        constructor : {
            value : MyStream
        }
    });
     
    Object.create will correctly setup the prototype chain 
    
    in the case of readable the options are 
    highWaterMark, the number of bytes to store in the internal buffer before pausing reading from the underlying data source 
    encoding, causes the buffer to be automatically decoded, possible values include utf8 and ascii 
    objectMode, allows the stream to behave as a stream of objects rather than bytes 
    
    + implement a readable stream, provide higher-level interface that would otherwise be possible with underlying data. inherit from stream.Readable and creating a _read(size) method 
    
    var stream = require('stream');
    var util = require('util');
    var fs = require('fs');
    
    function JSONLineReader(source) {
    	stream.Readable.call(this);
    	this._source = source;
    	this._foundLineEnd = false;
    	this._buffer = '';
    	source.on('readable', function () {
    		this.read();
    	}).bind(this));
    }
    
    util.inherits(JSONLineReader, stream.Readable);
    
    JSONLineReader.prototype._read = function (size) {
    	var chunk;
    	var line;
    	var lineIndex;
    	var result;
    	if (this._buffer.length === 0) {
    		chunk = this._source.read();
    		this._buffer += chunk;
    	}
        
    	lineIndex = this._buffer.indexOf('\n');
        
    	if (lineIndex !== -1) {
    		line = this._buffer.slice(0, lineIndex);
    		if (line) {
    			result = JSON.parse(line);
    			this._buffer = this._buffer.slice(lineIndex + 1);
    			this.emit('object', result);
    			this.push(util.inspect(result));
    		} else {
    			this._buffer = this._buffer.slice(1);
    		}
    	}
    };
    
    var input = fs.createReadStream(__dirname + '/json-lines.txt', {
    		encoding : 'utf8'
    	});
        
    var jsonLineReader = new JSONLineReader(input);
    
    jsonLineReader.on('object', function (obj) {
    	console.log('pos:', obj.position, '- letter:', obj.letter);
    });
     
    + a stream configured to use objectMode 
    var stream = require('stream');
    var util = require('util');
    util.inherits(MemoryStream, stream.Readable);
    
    function MemoryStream(options) {
    	options = options || {};
    	options.objectMode = true;
    	stream.Readable.call(this, options);
    }
     
    MemoryStream.prototype._read = function (size) {
    	this.push(process.memoryUsage());
    };
    var memoryStream = new MemoryStream();
    memoryStream.on('readable', function () {
    	var output = memoryStream.read();
    	console.log('Type: %s, value: %j', typeof output, output);
    });
     
    + implement a writable stream by implement _write method  
    MyWritable.prototype._write = function (chunk, encoding, callback) {
    	this.customWriteOperation(chunk, function (err) {
    		callback(err); //
    	});
    }
     
        * chunks and encodings encoding argument is only relevent when strings are being ued instead of buffers, strings can be used by setting decodingStrings to false in the option 
     
    + duplex will need implement _read and _write 
    var stream = require('stream');
    HungryStream.prototype = Object.create(stream.Duplex.prototype, {
    		constructor : {
    			value : HungryStream
    		}
    	});
    function HungryStream(options) {
    	stream.Duplex.call(this, options);
    	this.waiting = false;
    }
    HungryStream.prototype._write = function (chunk, encoding, callback) {
    	this.waiting = false;
    	this.push('u001b[32m' + chunk + 'u001b[39m');
    	callback();
    };
    HungryStream.prototype._read = function (size) {
    	if (!this.waiting) {
    		this.push('Feed me data! > ');  //display 
    		this.waiting = true;
    	}
    };
    var hungryStream = new HungryStream();
    process.stdin.pipe(hungryStream).pipe(process.stdout);
     
    + transform streams are specifically designed for changing data, need implement the _transform method 
     
    + advanced patterns and optimization, read data from a file but concerned about either speed or memory performance 
    
    optimize stream's buffer size to suite your app 
     
    var fs = require('fs');
    var zlib = require('zlib');
    function benchStream(inSize, outSize) {
    	var time = process.hrtime();
    	var watermark = process.memoryUsage().rss;
    	var input = fs.createReadStream('/usr/share/dict/words', {
    			bufferSize : inSize
    		});
    	var gzip = zlib.createGzip({
    			chunkSize : outSize
    		});
    	var output = fs.createWriteStream('out.gz', {
    			bufferSize : inSize
    		});
    	var memoryCheck = setInterval(function () {
    			var rss = process.memoryUsage().rss;
    			if (rss > watermark) {
    				watermark = rss;
    			}
    		}, 50);
    	input.on('end', function () {
    		var memoryEnd = process.memoryUsage();
    		clearInterval(memoryCheck);
    		var diff = process.hrtime(time);
    		console.log([
    				inSize,
    				outSize,
    				(diff[0] * 1e9 + diff[1]) / 1000000,
    				watermark / 1024].join(', '));
    	});
    	input.pipe(gzip).pipe(output);
    	return input;
    }
     
    console.log('file size, gzip size, ms, RSS');
    var fileSize = 128;
    var zipSize = 5024;
    function run(times) {
    	benchStream(fileSize, zipSize).on('end', function () {
    		times--;
    		fileSize *= 2;
    		zipSize *= 2;
    		if (times > 0) {
    			run(times);
    		}
    	});
    }
    run(10);
    ((callout - streams - buffer - size - 8))
    
    + using the old streams api, use stream.Readable class 
     
    + adapting streams based on their destination, make a stream behave differently when it's piped to the TTY 
     
    bind a listener to the pipe event and then use stream.isTTY to check if the stream s bound to a terminal 
    // A simple writable stream
    function OutputStream() {
    	stream.Writable.call(this);
    	this.on('pipe', function (dest) {
    		dest.isTTY = this.isTTY;
    	}
    		.bind(this));
    }
    OutputStream.prototype._write = function (chunk, encoding, cb) {
    	util.print(chunk.toString());
    	cb();
    };
    var memoryStream = new MemoryStream();
    
    + testing streams, use some suitable sample data and then call read() or write 
     
- file system 
    + fs module allws developer to interact with 
    POSIX file i/o prmitives 
    file streaming 
    bulk file i/o 
    file watching 
    
    + asynchronous and synchronous approaches for loading configuration files 
    working with the file descriptors 
    advisory file-locking techniques 
    recursive file operations 
    writing a file database 
    watching for file and directory changes 
    
    + POSXI file I/O wrappers, http://mng.bz/7EKM, wrapper module such as readdir 
    var fs = require('fs');
    fs.readdir('/path/to/dir', function (err, files) {
    	console.log(files); // [ 'fileA', 'fileB', 'fileC', 'dirA', 'etc' ]
    });
    
    rename 
    truncate 
    ftruncate 
    chown 
    fchown 
    lchown 
    chmod 
    fchmod, takes a file descriptor 
    lchmod, does not follow link 
    stat 
    lstat 
    fstat 
    link 
    symlink 
    readlink 
    realpath 
    unlink 
    rmdir 
    mkdir 
    readdir 
    close 
    open 
    utimes 
    futimes 
    fsync 
    write 
    read 
    
    var fs = require('fs');
    var assert = require('assert');
    var fd = fs.openSync('./file.txt', 'w+');
    var writeBuf = new Buffer('some data to write');
    fs.writeSync(fd, writeBuf, 0, writeBuf.length, 0);
    var readBuf = new Buffer(writeBuf.length);
    fs.readSync(fd, readBuf, 0, writeBuf.length, 0);
    assert.equal(writeBuf.toString(), readBuf.toString());
    fs.closeSync(fd);
    
    + streaming, fs provde a streaming API, fs.createWriteStream, fs.createReadSream
    
    + Bulk file I/O, for reading fs.readFile and writing fs.writeFile or appending, fs.appendFile 
    
    it handle a entire file into memory or disk 
    
    + file watching fs.watch, fs.watchFile 
    
    + synchronous alternative, sychronous API should be used when setting up your app 
    var fs = require('fs');
    var http = require('http');
    fs.readFileSync('./output.dat');
    http.createServer(function (req, res) {
    	fs.readFileSync('./output.dat');
    }).listen(3000);
    
    + loading and configuration files,
    
    we could use synchronous fs method 
    
    we could also use require to load json file into memory 
    
    + using a file descriptor, use fs file descriptor method, stdin, stdout, stderr 
    
    fs.writeSync(1, 'logging to stdout');
    
    + working with locking, set up a file-locking mechanism using node's built-ins 
     (https://kernel.org/doc/Documentation/filesystems/mandatory-locking.txt)
    
    Node has no built-in support for locking a file directly (either mandatory or advisory). But advisory locking of files can be done using syscalls such as flock (http://linux.die.net/man/2/flock), which is available in a third-party module (http://github.com/ audehlo/node-fs-ext).
    
    + creating lockfiles with mkdir 
    
    + recursive file operations, use recursion and combine file system primitives 
    fs.readdir/fs.readdirSync 
    fs.stat/fs.statSync, give information about file 

    var fs = require('fs');
    var join = require('path').join;
    exports.findSync = function (nameRe, startPath) {
    	var results = [];
    	function finder(path) {
    		var files = fs.readdirSync(path);
    		for (var i = 0; i < files.length; i++) {
    			var fpath = join(path, files[i]);
    			var stats = fs.statSync(fpath);
    			if (stats.isDirectory())
    				finder(fpath);
    			if (stats.isFile() && nameRe.test(files[i]))
    				results.push(fpath);
    		}
    	}
    	finder(startPath);
    	return results;
    }
    
    + writing a file database using in-memory database with append-only journaling 
    var Database = require('./database');
    var client = new Database('./test.db');
    client.on('load', function () {
    	var foo = client.get('foo');
    	client.set('bar', 'my sweet value', function (err) {
    		if (err)
    			return console.error(err);
    		console.log('write successful');
    	});
    	client.del('baz');
    });
    
    each line in the file is a record and it's a JSON object 
    
    + watch file and directory 
    fs.watch and fs.watchFile 
    
    The preferred is fs.watch, but since it’s inconsistent across platforms, it’s a good idea to test whether it does what you want (and better to have a test suite).
    
- networking 
    + network in node, network layers, packets, sockets 
    
    + networking terminology, TCP, transmission control protocol and UDP user datagram protocol 
    
    network concepts 
    layer 
    http 
    tcp 
    udp 
    socket 
    packet 
    datagram, the udp equivalent of a packet 
    MTU, maximum transimission unit 
    
        * layers 
        application     dns, http, irc 
        transport       tcp, udp 
        network         ip, icmp 
        data link       802.3(ethernet), wifi(ieee 802.11)
        physical        10BASE-5, bluetooth, fiber optics 
        
        tcp packet {receiver port, sender port} <- ip packet{receiver address, sender address} <- ethernet packet {receiver mac, sender mac}

    ip protocol doesn't guarantee data integrity or delivery, so we need a transport layer TCP. if the delivery isn't always required then UDP is preferred 
    
    port number is used to specify the data is relative to which program 
    
    + sockets, the basic unit of a network, historically socket meant the Berkeley Sockets API 
    
    if a application need to use both TCP and UDP then convention is to use the same port number 
    
    in node TCP socket could be create with net moule, UDP is supported by dgram module. other protocol are also supported such as DNS 
    
    + node's networking modules, DNS, TCP, HTTP and encryption
    
        * DNS, domain name system
        * HTTP
        * ENCRYPTION, the term SSL, secure sockets layer, node's tls module is implemented using OpenSSL 
        
        the type of encryption is called public key cryptography
        
    + non blocking networking and thread pools 
    
    BSD socket library libuv can make non-blocking TCP and UDP connections 
    
    (http://nikhilm.github.io/uvbook/networking.html#tcp)
    
    + TCP clients and servers 
    net.createServer 
    server.listen to bind it to a port 
    
    var assert = require('assert');
    var net = require('net');
    var clients = 0;
    var expectedAssertions = 2;
    
    var server = net.createServer(function (client) {
    		clients++;
    		var clientId = clients;
    		console.log('Client connected:', clientId);
    		client.on('end', function () {
    			console.log('Client disconnected:', clientId);
    		});
    		client.write('Welcome client: ' + clientId + 'rn');
    		client.pipe(client);
    	});
    server.listen(8000, function () {
    	console.log('Server started on port 8000');
    });
    
    + testing tcp server with client 
    net.connet to connect server's port 
    
    function runTest(expectedId, done) {
    	var client = net.connect(8000);
    	client.on('data', function (data) {
    		var expected = 'Welcome client: ' + expectedId + '\r\n';
    		assert.equal(data.toString(), expected);
    		expectedAssertions--;
    		client.end();
    	});
    	client.on('end', done);
    }
    runTest(1, ()=>{runtest(2, ()=>{});});
    
    if want to hanlde error then subscribe the error event on EventEmitter. for handling distinct network connections, it's better to use domain module to handle seperated event in a centralize way 
    
    + improve low-latency applications 
    socket.setNoDelay, to enable TCP_NODELAY
    
    server <=> buffer <=> client 
    
    Nagle’s algorithm, Nagle's algorithm is a means of improving the efficiency of TCP/IP networks by reducing the number of packets that need to be sent over the network. It was defined by John Nagle while working for Ford Aerospace and Communications Corporation.
    
    for real time application need to set the TCP_NODELAY flag to disable the nagle's algorithm 
    
    var net = require('net');
    var server = net.createServer(function (c) {
    		c.setNoDelay(true);
    		c.write('377375042377373001', 'binary');
    		console.log('server connected');
    		c.on('end', function () {
    			console.log('server disconnected');
    			server.unref();
    		});
    		c.on('data', function (data) {
    			process.stdout.write(data.toString());
    			c.write(data.toString())
    		});
    	});
    server.listen(8000, function () {
    	console.log('server bound');
    });
    
    + UDP clients and servers,  UDP is suitable for query-response protocols, which is used for DNS. if you want a lower latency over data integrity then UDP is good choice. online games generally use UDP 
    
    for example build a video streaming service, display images 
    
    + transferring a file with UDP, use the dgram module to create datagram sockets and send data with socket.send 
    
    var dgram = require('dgram');
    var socket = dgram.createSocket('udp4');
    socket.bind(4000);
    
    //create a client socket is the same as servers use dgram.createSocket 
    var message = 'Sample message';
    socket.send(new Buffer(message), 0, message.length, port, remoteIP);
    
        * example 
        
    var dgram = require('dgram');
    var fs = require('fs');
    var port = 41230;
    var defaultSize = 16;
    function Client(remoteIP) {
        var inStream = fs.createReadStream(__filename);
        var socket = dgram.createSocket('udp4');
        inStream.on('readable', function () {
            sendData();
        });
        function sendData() {
            var message = inStream.read(defaultSize);
            if (!message) {
                //When client has finished,call unref to safely close it when no longer needed
                return socket.unref();
            }
            socket.send(message, 0, message.length, port, remoteIP,
                function (err, bytes) {
                sendData();
            });
        }
    }
    function Server() {
        var socket = dgram.createSocket('udp4');
        socket.on('message', function (msg, rinfo) {
            process.stdout.write(msg.toString());
        });
        socket.on('listening', function () {
            console.log('Server ready:', socket.address());
        });
        socket.bind(port);
    }
    if (process.argv[2] === 'client') {
        new Client(process.argv[3]);
    } else {
        new Server();
    }
    
    + datagram packet layout and datagram size, package size must be under the MTU on the network 
    
    source port, 0-15 
    desitination port, 16-31 
    udp length, 0-15 
    upd checksume, 16-31 
    payload 
    
    the MTU is 65507 bytes for ipv4 and 65527 for ipv6 
    
    + binary communication with udp 
    chat servers are the classic network programming it uses UDP instead of TCP or HTTP 
    
    when a client connected you could write client.write 
    
    client server program allows client to connect to a cntral server over udp and message each other. UDP isn't full-duplex, it's possible to create connections in two directions given a port number at both sides 
    
    var assert      = require('assert');
    var dgram       = require('dgram');
    var fs          = require('fs');
    var defaultSize = 16;
    var port        = 41234;
    function Client(remoteIP) {
    	var socket = dgram.createSocket('udp4');
    	var readline = require('readline');
    	var rl = readline.createInterface(process.stdin, process.stdout);
    	socket.send(new Buffer('<JOIN>'), 0, 6, port, remoteIP);
    	rl.setPrompt('Message> ');
    	rl.prompt();
    	rl.on('line', function (line) {
    		sendData(line);
    	}).on('close', function () {
    		process.exit(0);
    	});
    	socket.on('message', function (msg, rinfo) {
    		console.log('\n<' + rinfo.address + '>', msg.toString());
    		rl.prompt();
    	});
    	function sendData(message) {
    		socket.send(new Buffer(message), 0, message.length, port, remoteIP,
    			function (err, bytes) {
    			console.log('Sent:', message);
    			rl.prompt();
    		});
    	}
    }
    function Server() {
    	var clients = [];
    	var server = dgram.createSocket('udp4');
    	server.on('message', function (msg, rinfo) {
    		var clientId = rinfo.address + ':' + rinfo.port;
    		msg = msg.toString();
    		if (!clients[clientId]) {
    			clients[clientId] = rinfo;
    		}
    		if (msg.match(/^</)) {
    			console.log('Control message:', msg);
    			return;
    		}
    		for (var client in clients) {
    			if (client !== clientId) {
    				client = clients[client];
    				server.send(
    					new Buffer(msg), 0,
    					msg.length, client.port, client.address,
    					function (err, bytes) {
    					if (err)
    						console.error(err);
    					console.log('Bytes sent:', bytes);
    				});
    			}
    		}
    	});
    	server.on('listening', function () {
    		console.log('Server ready:', server.address());
    	});
    	server.bind(port);
    }
    module.exports = {
    	Client : Client,
    	Server : Server
    };
    if (!module.parent) {
    	switch (process.argv[2]) {
    	case 'client':
    		new Client(process.argv[3]);
    		break;
    	case 'server':
    		new Server();
    		break;
    	default:
    		console.log('Unknown option');
    	}
    }
    
    + HTTP clients and servers, http protocol is stateless and built on TCP node's http module is on top its TCP module 
    
        * http server 
        http.createServer and http.createClient 
        
        var assert = require('assert');
        var http = require('http');
        var server = http.createServer(function (req, res) {
                res.writeHead(200, {
                    'Content-Type' : 'text/plain'
                });
                res.write('Hello, world.\r\n');
                res.end();
            });
        server.listen(8000, function () {
            console.log('Listening on port 8000');
        });
        var req = http.request({
                port : 8000
            }, function (res) {
                console.log('HTTP headers:', res.headers);
                res.on('data', function (data) {
                    console.log('Body:', data.toString());
                    assert.equal('Hello, world.\r\n', data.toString());
                    assert.equal(200, res.statusCode);
                    server.unref();
                });
            });
        req.end();
        
        
        high level node http module like express and restify. it's typical to create and tear down TCP socket per request for HTTP in TCP connection 
        
        * flow redirects, with request module, download pages and follow redirects if necessary. the response code 3xx
        300 multiple choices 
        301 moved permanently 
        302 found 
        303 see other 
        304 not modified 
        305 see proxy 
        307 temporary redirect 
        
        Redirection is cyclical, and requests will be made until a 200 status is encountered
        
        var http = require('http');
        var https = require('https');
        var url = require('url');
        var request;
        function Request() {
            this.maxRedirects = 10;
            this.redirects = 0;
        }
        Request.prototype.get = function (href, callback) {
            var uri = url.parse(href);
            var options = {
                host : uri.host,
                path : uri.path
            };
            var httpGet = uri.protocol === 'http:' ? http.get : https.get;
            console.log('GET:', href);
            function processResponse(response) {
                if (response.statusCode >= 300 && response.statusCode < 400) {
                    if (this.redirects >= this.maxRedirects) {
                        this.error = new Error('Too many redirects for: ' + href);
                    } else {
                        this.redirects++;
                        href = url.resolve(options.host, response.headers.location);
                        return this.get(href, callback);
                    }
                }
                response.url = href;
                response.redirects = this.redirects;
                console.log('Redirected:', href);
                function end() {
                    console.log('Connection ended');
                    callback(this.error, response);
                }
                response.on('data', function (data) {
                    console.log('Got data, length:', data.length);
                });
                response.on('end', end.bind(this));
            }
            httpGet(options, processResponse.bind(this))
            .on('error', function (err) {
                callback(err);
            });
        };
        request = new Request();
        request.get('http://google.com/', function (err, res) {
        	if (err) {
        		console.error(err);
        	} else {
        		console.log('Fetched URL:', res.url,
        			'with', res.redirects, 'redirects');
        		process.exit();
        	}
        });
        
        * http proxies, for capture and retransmit htt requests 
        var http = require('http');
        var url = require('url');
        http.createServer(function (req, res) {
        	console.log('start request:', req.url);
        	var options = url.parse(req.url);
        	options.headers = req.headers;
        	var proxyRequest = http.request(options, function (proxyResponse) {
        			proxyResponse.on('data', function (chunk) {
        				console.log('proxyResponse length:', chunk.length);
        				res.write(chunk, 'binary');
        			});
        			proxyResponse.on('end', function () {
        				console.log('proxied request ended');
        				res.end();
        			});
        			res.writeHead(proxyResponse.statusCode, proxyResponse.headers);
        		});
        	req.on('data', function (chunk) {
        		console.log('in request length:', chunk.length);
        		proxyRequest.write(chunk, 'binary');
        	});
        	req.on('end', function () {
        		console.log('original request ended');
        		proxyRequest.end();
        	});
        }).listen(8080);
        
        * making DNS requests, DNS uses TCP and UDP for its request/response-based protocol, dns module 
        
        when http or net modules are used to connect remote server, node will look up ip addreses using dns.lookup internally 
        
        dns.resolve 
        dns.resolveTxt, text values can be used by other services for addtional features built on top of dns 
        dns.resolveSrv, service records define "location" data for a service 
        dns.resolveNs, used for name server themselves 
        dns.resolveCname, canonical name records, these are set to domain names rather than ip address 
        
        dns module is used for look up a single or multiple domain names quickly. When looking up multiple addresses, it can be faster to use dns.resolve instead.
        
        var dns = require('dns');
        dns.lookup('www.manning.com', function (err, address) {
        	if (err) {
        		console.error('Error:', err);
        	}
        	console.log('Addresses:', address);
        });
        
        var dns = require('dns');
        //the result return an array of address compare to previous 
        dns.resolve('www.manning.com', function (err, addresses) {
        	if (err) {
        		console.error(err);
        	}
        	console.log('Addresses:', addresses);
        });
        
        * encryption, node's encryption module, tls uses OpenSSL transport layer security/secure socket layer 
        
        tls module is used as the basis for the https module
        
        Public key cryptography is dependent on public-private key pairs a pair is required for both clients and servers. public key of the Certificate Authority(CA)
        
        The OpenSSL command-line tools are required for this. http://www.openssl.org 
        
        to make a certificate signed by an authority you control, you'll need to issue the following commands 
        genrsa, generate an RSA certificate; this is private key 
        req, create a CSR, X.509 Certificate signing Request 
        x509, sign the private key with the CSR to produce a public key 
        
        //create server's private key using 1024 bit 
        $ openssl genrsa -out server.pem 1024
        //create CSR this is where you enter your hostname 
        $ openssl req -new -key server.pem -out server-csr.pem
        //sign server's private key 
        $ openssl x509 -req -in server-csr.pem -signkey server.pem -out server-cert.pem
        //create client's private key 
        $ openssl x509 -req -in server-csr.pem -signkey server.pem -out server-cert.pem
        //create CSR for the client remeber to enter your hostname here as well 
        $ openssl req -new -key client.pem -out client-csr.pem
        //sign client's private key and output a public key 
        $ openssl x509 -req -in client-csr.pem -signkey client.pem -out client-cert.pem
        
        after generate the certificate files start the server using tls.createServer 
        
        var fs = require('fs');
        var tls = require('tls');
        var options = {
        	key : fs.readFileSync('server.pem'),
        	cert : fs.readFileSync('server-cert.pem'),
        	ca : [fs.readFileSync('client-cert.pem')],
        	requestCert : true
        };
        var server = tls.createServer(options, function (cleartextStream) {
        		var authorized = cleartextStream.authorized ?
        			'authorized' : 'unauthorized';
        		console.log('Connected:', authorized);
        		cleartextStream.write('Welcome!\n');
        		cleartextStream.setEncoding('utf8');
        		cleartextStream.pipe(cleartextStream);
        	});
        server.listen(8000, function () {
        	console.log('Server listening');
        });
        
        * encrypted web servers and clients https.createServer with TLS 
        //server 
        var fs = require('fs');
        var https = require('https');
        var options = {
        	key : fs.readFileSync('server.pem'),
        	cert : fs.readFileSync('server-cert.pem'),
        	ca : [fs.readFileSync('client-cert.pem')],
        	requestCert : true
        };
        var server = https.createServer(options, function (req, res) {
        		var authorized = req.socket.authorized
        			 ? 'authorized' : 'unauthorized';
        		res.writeHead(200);
        		res.write('Welcome! You are ' + authorized + '\n');
        		res.end();
        	});
        server.listen(8000, function () {
        	console.log('Server listening');
        });
        
        //client 
        var fs = require('fs');
        var https = require('https');
        var os = require('os');
        var options = {
        	key : fs.readFileSync('client.pem'),
        	cert : fs.readFileSync('client-cert.pem'),
        	ca : [fs.readFileSync('server-cert.pem')],
        	hostname : os.hostname(),
        	port : 8000,
        	path : '/',
        	method : 'GET'
        };
        var req = https.request(options, function (res) {
        		res.on('data', function (d) {
        			process.stdout.write(d);
        		});
        	});
        req.end();
        req.on('error', function (e) {
        	console.error(e);
        });
        
- child process 
    + write everything in javascript, projects 
    GaphicsMagic, http://www.graphicsmagick.org/, a full-featured image manipulation tool 
    wkhtmltopdf, http://wkhtmltopdf.org/, a headless webkit pdf geenrator perfect for turning that html report into a pdf download 
    
    choosing the right method, to execute external applications 
    
    /external app 
        /non-node 
            /streaming -no-> spawn 
            /buffered(callback) -no-> execFile 
                                -yes-> exec 
        /node 
            /streaming -no-> fork 
            
        * execFile, execute an external app, given a set of arguments and callback with buffered output after the process exits 
        * spawn, execute an external application, given a set of arguments and provide a streaming interface for i/o and events for when the process exists 
        * exec, execute one or more commands inside a shell and callback with the buffered output after the process exits 
        * fork, execute a node module as a separate process, given a set of arguments provide a streaming and evented interface like spawn 
    
    
    + execute external applications 
    var cp = require('child_process');
    cp.execFile('ls', ['non-existent-directory-to-list'],
    	function (err, stdout, stderr) {
    	console.log(err.code);
    	console.log(stderr);
    });
    
        * execute external app and stream output 
        cp.execFile('echo', ['hello', 'world'], ...);
        cp.spawn('echo', ['hello', 'world'], ...);
        
        var cp = require('child_process');
        var child = cp.spawn('echo', ['hello', 'world']);
        child.on('error', console.error);
        child.stdout.pipe(process.stdout);
        child.stderr.pipe(process.stderr);
        
        
        * executing commands in a shell 
        cp.exec('cat messy.txt | sort | uniq',
            function (err, stdout, stderr) {
            console.log(stdout);
        });
    + detaching a child process, can be used to kick off external applications and then allow them to run on their own 
    
    var child = cp.spawn('./longrun', [], { detached: true });
    
        * execute node programs 
        var cp = require('child_process');
        cp.execFile('node', ['myapp.js', 'myarg1', 'myarg2' ], ...
        
        * forking node modules for manage separate node processes 
        var cp = require('child_process');
        var child = cp.fork('./myChild');
        
        child process will share i/o of parent and setup a communication channel 
        On the parent side, it provides child.on('message') and child.send().
        
        * running jobs use fork to run a pool of workers 
        
        * working synchronously execFileSync, spawnSync, execFile 


# Real-word recipes 
- the web, build leaner and meaner web applications 
    + using node for client-side development 
        * front end techniques 
        quick start a web server for single page app 
        
        var connect = require('connect');
            connect.createServer(
            connect.static(__dirname)
        ).listen(8080);
        
        http.createServer 
        
        other modules,  GitHub at https://github.com/jarofghosts/glance, and on npm as glance
        
        * grunt for client-side project 
        install grunt-cli 
        make a package.json 
        use a grunt plugin that runs a webserver 
        
        Now you need to install a web server module: npm install --save-dev grunt grunt-contrib-connect will do the job.
        
        gulp, http://gulpjs.com/ is a new alternative option which take advantage of node's streaming api and has a light syntax and easy to learn 
        
        create a file called Gruntfiles.js which contain tasks that grunt will run for you 
        
        * using the dom in node, jsdom, https://github.com/tmpvar/jsdom, then we could use jQuery in node 
        
        var jsdom = require('jsdom');
        jsdom.env(
        	'<p class="intro">Welcome to Node in Practice</p>',
        	['http://code.jquery.com/jquery.js'],
        	function (errors, window) {
        	console.log('Intro:', window.$('.intro').text());
        });
        
        another options is If you really just want to process HTML in a jQuery-like way, then you could use cheerio https://npmjs.org/package/cheerio. This module is more suited to web scraping
        https://github.com/cheeriojs/cheerio
        
    + node in the browser, use a browserify program for help converting node javascript into browser-friendly code. http://browserify.org/
    
    convert ndoe module to browserify script by 
    $ browserify index.js o bundle.js 
    any require statements will cause the files to be included in bundle.js 
    
    create a package.json file with jquery as a dependency, you can load jquery using browserify 
    
    //use browserify in code 
    var browserify = require('browserify');
    var b = browserify();
    b.add('./index.js');
    b.bundle().pipe(process.stdout);
    
    + server-side techniques and websockets 
        * express route separation 
        app.get('/notes', function (req, res, next) {
        	db.notes.findAll(function (err, notes) {
        		if (err)
        			return next(err);
        		res.send(notes);
        	});
        });
        app.post('/notes', function (req, res, next) {
        	db.notes.create(req.body.note, function (err, note) {
        		if (err)
        			return next(err);
        		res.send(note);
        	});
        });
        
        * refactor web app structure 
        create a directory called routes or controllers and add a file called index.js
        
        each routing function is exported with a CRUD-inspired name(index, create, update, show)
        
        var express = require('express');
        var app = express();
        var routes = require('./routes');
        app.use(express.bodyParser());
        app.get('/notes', routes.notes.index);
        app.post('/notes', routes.notes.create);
        app.patch('/notes/:id', routes.notes.update);
        app.get('/notes/:id', routes.notes.show);
        
        module.exports = app;
        
        * automatic restart the server, use a file watcher to restart th application automatically 
        
        node provide an API for this, fs.watch
        
        third party module is One of the most widely used modules that solves this problem is Remy Sharp’s nodemon (http://nodemon.io/). Nodemon is a utility that will monitor for any changes in your source and automatically restart your server. 
        
        //reload node process 
        var fs = require('fs');
        var exec = require('child_process').exec;
        function watch() {
        	var child = exec('node server.js');
        	var watcher = fs.watch(__dirname + '/server.js', function (event) {
        			console.log('File changed, reloading.');
        			child.kill();
        			watcher.close();
        			watch();
        		});
        }
        watch();
        
        * configuring web applications, use json configuration files, use process.evn to access system environment variables  
        
        example for how express app manage the configuration 
        var express = require('express');
        var app = express();
        app.set('port', process.env.PORT || 3000);
        app.configure('development', function () {
        	app.set('db', 'localhost/development');
        });
        app.configure('production', function () {
        	app.set('db', 'db.example.com/production');
        });
        app.listen(app.get('port'), function () {
        	console.log('Using database:', app.get('db'));
        	console.log('Listening on port:', app.get('port'));
        });
        
        //json configuration loader 
        var config = {
        	development : require('./development.json'),
        	production : require('./production.json'),
        	test : require('./test.json')
        };
        module.exports = config[process.env.NODE_ENV
        
        The web framework Flatiron (http://flatironjs.org/) has an application configuration module called nconf (https://npmjs.org/package/nconf) that handles configuration files, environmental variables, and command-line options
        
        * elegant error handling 
        
        
        
    
    + migrating express 3 applications to express 4 
    + testing web applications 
    + full-stack frameworks and realtime services 
    
- 

- tests, the key to confident code 
- debugging designing for introspection and resolving issues 
- node in production, deploying applications safely 


# Writing modules 
- writing modules, mastering what node is all about 








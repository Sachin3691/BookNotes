Refactoring JavaScript=Evan;Note=Erxin


# What is refactoring? 
- how can you guarantee behavior doesn't change?
Details of implementation	
Unspecified and untested behavior	
Performance

- Refactoring: Improving the Design of Existing Code (Addison-Wesley), would prove extremely difficult.

- We Care About Unspecified and Untested Behavior? We can’t refactor it, because we won’t be able to verify that the behavior doesn’t change

- But by that time, we should have tests in place to verify inputs and outputs. When we have tests in place, then we have enough confidence to refactor our code and change the implementation.

- Adding a few lines of frontend code that don’t get minimized will increase the time for downloading and processing

- Balancing Quality and Getting Things Done

Extract functions and modules to simplify interfaces
Verify code behavior through tests
Avoid impure functions when possible
Name variables and functions well

- what is and isn't refactoring they create new code and features:

Adding square root functionality to a calculator application
Creating an app/program from scratch
Rebuilding an existing app/program in a new framework
Adding a new package to an application or program
Addressing a user by first and last name instead of first name
Localizing
Optimizing performance
Converting code to use a different interface 


# Which JavaScript are you using 
- statistic 
version, specification 
platforms and implementation 
frameworks 
libraries 

- es6 feature tables 
https://kangax.github.io/compat-table/es6/

- precompile script, babel.js, jsx 


# Testing 
- terms 
coverage 
high-level, low-level 
complexity 
confidence 
exercised 
technical debet 
feedback loop 
mocking and stubbing 

- many whys of testing 
refactoring is impossible without it 
makes working with a team easier 
tests are ideal for demonstrating functionality
not just verify the behavior of your code 
tests are crucial for big upgrades
catch bugs early 
tests help you smooth out development cycles 
your feedback loop will be tighter 

- many ways of testing 
    + “end-to-end” tests could be called integration tests, system tests, functional tests, or something else depending on the context
    
    + Confidence is the goal. Tests are a practical way of creating specific types of confidence in the code
    
    + manual testing 
    If you’re faced with an undertested codebase, it’s a good way to experiment. This applies to the feature and debugging level of development as well.
    
    + documented manual testing 
    sometimes the fastest way to get a section of code “covered” is by writing a detailed set of steps to execute the relevant code paths.

    + approval tests 

    development and approval are two distinct processes, where does the canonical list of approved/unapproved tests/checklists

    list of features be contained within the source code
    how can you avoid slowing test cycles 
    Will be developers see approval tests passing as completion of a task?
    These high-level APIs are useful for end-to-end tests, but be wary of frameworks that try to automate the actual acceptance of tasks.
    
- end-to-end tests, These tests are slow and simulate end users’ experience.
- unit tests, Having slow tests (end-to-end) and fast tests (unit) to differentiate this behavior would be ideal

- nonfunctional testing 
performance testing 
usability testing 
play testing 
security testing 
accessibility testing 
localization testing 

- other test types of interest 
feature tests 
regression tests 
characterization tests, You write these for untested code to add coverage. 

- tools and processes 
    + coding standards and style guids 

    style guide and include specifics like “Use const and let instead of var” as well as more general guidelines like “All new code must be tested” and “All bug fixes must have a test that reproduces the bug.” 
    
    + developer happiness meeting, short meeting sometimes referred to as a developer happiness (this name may not be well received by noncoders in the organization), engineering quality, or technical debt meeting. The purpose of the meeting is to recognize areas in the codebase that have quality problems worth addressing. 

    + pair programming, wo programmers tackle a problem, side-by-side, with one person running the keyboard (“driving”) while the other watches the screen and sometimes has an additional computer available for research and quick sanity checks without tying up the main development machine

    + code review 
    
    + TDD, no code is written that does not have coverage, and therefore, no code is written that cannot be refactored.
    
    + red/green/refactor cycle of BDD end-to-end tests, there are smaller red/green/refactor cycles for TDD’d unit tests.

    + tools for quality 
    version control 
    test frameworks 
    assertion/expectation syntax libraries 
    domain-specific libraries 
    factories and fixtures 
    mocking/stubbing libraries 
    build/task/packaging tools 
    loaders and watchers 
    test run parallelizers 
    continuous integration services 
    coverage reporters 
    
    + style checkers, aka linters 
    + debuggers/loggers 
    + staging/qa servers 



# Testing in action 
- use debugger  debugger by running node debug my-program-name.js instead of node my-program-name.js.

- set breakpoint with 

debugger;

- untested code and characterization tests 

-  Along the way, try not to insult the programmers who wrote the legacy code, whether they’re still with the team or not. 



# Basic refactoring goals 
# Refactoring javascript 
- Magic numbers	Long lines, part 1	
Inlining function calls	Introducing a variable	
Variable hoisting (including a discussion of function hoisting)
 
# Refactoring functions and objects 
- new features of ecs6
Array alternative: sets	Array alternative: objects	Object alternative: maps	Array alternative: bit fields

- WeakSet and WeakMap. The main differences between them and their “strong” (normal strength?) counterparts are:	They cannot be iterated (no forEach function).	They do not have a reference to their size.	WeakSet cannot store primitives.	They hold their keys “weakly”; that is, the keys are available for garbage collection when they don’t have any references.


# Refactoring within a hierarchy
- solve problems like 
One huge file containing all of the code
One huge (flat) directory containing all of the code
One huge object or function containing all of the code

- build a hierarchy, type system is also can replace the enum 

Sometimes you’ll prefer a simple conditional to subclassing. Other times, you may want to skip both the subclassing and the conditional altogether (see “Strategy”).

There’s a “nonstandard” yet popular alternative to Object.getPrototypeOf(thing), which you use like this: thing.__proto__.

- wreck our hierarchy 
Constructor functions	
Object literals	
Factory functions

- object literals 
- evaluating your options for hierarchies 
classes 
constructor functions 
object literals 
factory functions 

- bad practices like tight coupling of components, and encourages deep hierarchies and mutable state.

avoid deep hierarchies by abstract common methods into mixins, extend the class by the mixin 
    
entity-component systems, which tend to be used heavily in game development.

- antipatterns 
Hyperextension (hierarchy is too deep)	
Goat and cabbage raised by a wolf (parent and children have nothing in common)


# Refactoring to OOP patterns 
- keep the YAGNI, ya ain't gonna need it 

Here they are:

Template method
Strategy, The template method pattern allowed us to remove a conditional through subclassing. 
State, The state pattern is a bit more involved than the strategy pattern, but can flow naturally from it. 
null object, Consider how many conditional checks in your code are executed against null, A (Non-)Value Not Even a Father Could Love
Decorator (“Wrapper” section)
Adapter (“Wrapper” section)
Facade

- It takes one null to kick off a codebase full of conditional checks and sadness. Not only does every function that calls something that could return a null value likely need a null check

We’ll implement a NullString that not only has mirror functions, but also returns mirror values to the NameString.

// with null object
class Person {
  constructor(name){
    this.name = new NameString(name);
  }
};

class AnonymousPerson extends Person {
  constructor(){
    super();
    this.name = new NullString;
  }
};

class NullString{
  capitalize(){
    return this; // same as new NullString in this case
  };
  tigerify() {
    return this; // same as new NullString in this case
  };
  display() {
    return '';
  };
};

class NameString extends String{
  capitalize() {
    return new NameString(this[0].toUpperCase() + this.substring(1));
  };
  tigerify() {
    return new NameString(`${this}, the tiger`);
  };
  display(){
    return this.toString();
  };
}

personOne = new Person("tony");
personTwo = new AnonymousPerson("tony");
console.log(personOne.name.capitalize().tigerify().display());
console.log(personTwo.name.capitalize().tigerify().display());

- Wrapper (Decorator and Adapter)There are a few ways to implement the decorator pattern. One thing that should not be surprising based on earlier sections in this chapter is that JavaScript does not naturally fit in well with interfaces, abstract classes

 With a class or constructor function, the implicitly returned class would be of type WithoutNull, which is odd, and overriding it (returning a different object in the constructor function of the class or from a constructor function called with new) reads as a bit confusing.

-  it is odd to explicitly return something from a constructor function

So it’s not only the implementation, but also the interface, that suggests a factory function.

Adapter can remap the functions to new ones. This is the same problem that WithNull helped us solve earlier.

- But if we use a factory function for the adapter, what is the difference between an adapter and a decorator?

we might prefer to nest as in WithoutNullName(WithoutNullPhone(person)))

- the difference between an adapter and a decorator?

A decorator is more likely to have nested wrappers to add a few disparate traits. An adapter is more of a mapping of interfaces between one object and another.

Well, if we have control over the entire implementation (i.e., we own our own libraries), we might get the same utility from altering the base code rather than complicating our interfaces with wrapping possibilities.

- facade, Basically, a facade is an interface that contains a curated subset from one or more APIs with the intention of streamlining and simplifying the code one needs to write.

When should you not use a facade? Any time the direct interactions with an API are simple enough or understood well enough by you or other people interacting with it.

- Design Patterns: Elements of Reusable Object-Oriented Software (also known as the “Gang of Four” or “GoF” book for its four authors), as well as a good number of those that have popped up throughout the years

    + composite, This pattern is good for traversing trees of data, such as JSON/objects/document nodes.

    + builder, Used for complex object creation, this pattern is good for generating test data.

    + observer, This pattern can be seen in things like publish/subscribe, events, and observables.

    + prototype, This pattern is built into JavaScript. 
    
    + iterator, Building your own iterator is an unlikely choice given the wealth of native options for iteration

    + proxy, We actually see an example of this in action in Chapter 10 when we use the testdouble framework, which allows “faking out” the real function call as well as asserting that the function was called.



# Asynchronous refactoring 
- why async 

use asynchronous remote HTTP calls. If our remote call were synchronous, it would necessarily “stop the world” (STW) and keep our program waiting. 

- It is worth noting that setTimeout(myFunction, 300) doesn’t necessarily execute myFunction after 300 milliseconds. What it does is first return (in node, if you assign with x = setTimeout(myFunction, 300), you’ll see that it returns a Timeout object)

- The “pyramid of doom” refers to the shape where code creeps to the right with many levels of indentation. “Callback hell” 

prevent the callback hell, extracting functions into a containing object

const http = require('http');
const getBody = {
  bodyArray: [],
  saveBody: function(chunk){
    this.bodyArray.push(chunk);
  },
  printBody: function(){
    console.log(this.bodyArray.join(''))
  },
  getResult: function(result){
    result.on('data', this.saveBody.bind(this));
    result.on('end', this.printBody.bind(this));
  }
};

http.get('http://refactoringjs.com', getBody.getResult.bind(getBody));

- testing our asynchronous program 

$ node whatever-you-call-the-file.js. 

You can install it with npm install tape.

-  toward heavier tools like mocha (as we used earlier) for testing and Sinon.JS (which we haven’t looked at) for doubles. Or you might try out simpler tools like tape and testdouble. 

- callbacks and testings,  This is a property of continuation passing style (CPS) called inversion of control (IoC), and while useful, it has some drawbacks

    + It makes testing more difficult (although part of this is just the nature of asynchronous programming).
    
    + It’s hard to mix with synchronous code.
    
    + Return values are likely no longer important throughout the sequence of callbacks. 

- basic CPS and Ioc 

It doesn’t even have to be asynchronous. Here’s an example of a noncallback (aka “direct style”) version of our function

Our earlier example did not use CPS the whole way through. We relied on a nonlocal object to do some of the dirty work.

- promise, a callback to be executed by the function that is called. Return values become little better than meaningless, and instead the arguments passed from the callback (one is conventionally called result) become the focus of tests and subsequent callbacks.

// promises
four()
.then(addOne)
.then(console.log);


# Functional refactoring 
- To learn functional programming
you need to learn Scheme/Haskell
JS compile from PureScript, TypeScript, ClojureScript 
Category theory 

- declarative programming language that’s especially distant from JavaScript, you should look into Prolog.

- In a stateless world, there is no longer a question of when something happened. If two processing cores of a machine (or more) run the same function, they get the same result, and it doesn’t matter which finishes first. 

- basics, In JavaScript, the benefits and restrictions of programming in functional style are not as simple as a switch that can be flipped on and off

    + Avoiding Destructive Actions, Mutation, and Reassignment
    //instead of
    function func(x){
      if(x >= 2){
        x = x + 7;
      }
      return x;
    };
    
    //we can do 
    function func(x){
      if(x >= 2){
        return x + 7;
      } else {
        return x;
      }
    };

    // or

    function func(x){
      return x >= 2 ? x + 7 : x;
    };
    
    const we might prefer a memorized function
    
    + AVOIDING REASSIGNMENT IN LOOPS
    
    + Avoiding reassignment in conditional bodies
    function emailSubject(){
      return weKnowName ? `Hi ${name}` : "Hi"
    };

    + Another source of mutating values is through using “destructive” functions.

    + Referential Transparency and Avoiding State

    + Handling Randomness, this seed value cannot be set in our native Math.random function.If it could be set with a seed, we could generate the same “random” value sequence. 

    because you can have random-like numbers that you can test against. 

    + Keeping the Impure at Bay

    in functional style, we should prefer using explicit inputs and outputs to accessing and modifying a this value.

    I/O calls are side effects and make impure functions. Impure functions are hard to test.

- advanced basics 
   + currying, One functional concept that you can exploit to make your code more flexible is using currying and partial application.
   
function add(numberOne, numberTwo){
  return function(numberOne){
    numberOne + numberTwo;
  };
};

Ramda has the coolest name and graphic which is better than lodash 
$ npm instal ramda 
 
https://ramdajs.com/

//example 
R = require('ramda');
const square = (thing) => thing * thing;

const mapSquares = R.map(square);
console.log(mapSquares([2, 4, 5]));

console.log(R.map(square, [2, 4, 5]));
   
var factorial =   R.memoize(n => R.product(R.range(1, n + 1)));
   + partial application 
   + function composition 
   + types 

- function composition 
_ = require('lodash');
const square = (thing) => thing * thing;

const mapSquares = _.map(square);
console.log(mapSquares([2, 4, 5])); //error 
console.log(_.map(square, [2, 4, 5])); 

- That goes for R (for Ramda functions) and S (for Sanctuary functions and objects).

- Burritos 
    + Monoids 
    + Functors 
    + Applicatives 
    + Monads 
    + Maybe more?! 
    
- Introducing Sanctuary which is another library for functional programming. It enhanced type checking 
const {create, env} = require('sanctuary');
const S = create({checkTypes: true, env: env});
S.add("hello", 3);

//compare ramda 
R = require('ramda');
R.add("hello", 3);
// NaN

    + Functional Refactoring with Maybe

    S.maybeToNullable, we used S.fromMaybe to return a blank string ('') if the Maybe (Nothing or Just) is a Nothing. If it is a Just, it unwraps the value.
 
    + Functional Refactoring with Either

- deeper int functional programming 

some interesting options:

TypeScript
PureScript
ClojureScript
Elm

- Naive Bayes Classifier 
// naive_bayes_functional.js
R = require('ramda');

const smoothing = 1.01;

function wordCountForLabel(testWord, relevantTexts){
  const equalsTestword = R.equals(testWord);
  return R.filter(equalsTestword, _allWords(relevantTexts)).length;
};

function likelihoodOfWord(word, relevantTexts, numberOfTexts){
  return wordCountForLabel(word, 
                           relevantTexts) / numberOfTexts + smoothing;
};

function likelihoodByLabel(label, newWords, trainedSet){
  const relevantTexts = textsForLabel(trainedSet.texts, label)
  const initialValue = trainedSet.probabilities[label] + smoothing;
  const likelihood = R.product(
    newWords.map(newWord => 
      likelihoodOfWord(newWord, 
                       relevantTexts,
                       trainedSet.texts.length))) * initialValue;
  return {[label]: likelihood}
}

function textsForLabel(texts, label){
  return R.filter(text => text.label === label)(texts);
}

function _allWords(theTexts){
  return R.flatten(R.pluck('words', theTexts));
};

function addText(words, label, existingText = []){
  return R.concat(existingText, [{words: words, label: label}]);
};

function train(allTexts) {
  const overTextLength = R.divide(R.__, allTexts.length);
  return {texts: allTexts,
          probabilities: R.map(overTextLength, 
                               R.countBy(R.identity,
                                         R.pluck('label', allTexts)))};
};

function classify(newWords, trainedSet){
  const labelNames = R.keys(trainedSet.probabilities);
  return R.reduce((acc, label) => 
    R.merge(acc, likelihoodByLabel(label, newWords, trainedSet))
            , {}, labelNames);
};

module.exports = {_allWords: _allWords,
                  addText: addText,
                  train: train,
                  classify: classify}
                  





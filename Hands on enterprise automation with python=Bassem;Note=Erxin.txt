Hands on enterprise automation with python=Bassem;Note=Erxin

# Introduction 
- IDE pycharm
- 2.x or 3.x

Python 2.x and make it compatible with both versions, but you will need to import a few libraries first, such as the __future__ module, to make it backward compatible

- package search path,  sys module and printing the sys.path

__init__.py will mark the directy as a package. The code of it will be executed during import 

- network python libraries

    + Netmiko, multi-vendor library support SSHing and telnet for network devices 
    https://github.com/ktbyers/netmiko
    
    Support includes Cisco, Arista, Juniper, HP, Ciena, and many other vendors.

    + NAPALM, works as a wrapper for official vendor API. 

    https://github.com/napalm-automation/napalm


    + PyEZ, sed to manage and automate Juniper devices. It can perform CRUD operation on the device from the Python client. Output will be json or xml 
    
    https://github.com/Juniper/py-junos-eznc
    
    + infoblox-client, interact with infoblox NIOS over the interface based on a REST called WAPI 
    
    https://github.com/infobloxopen/infoblox-client
    
    + NX-API, a cisco nexus series API 

    https://developer.cisco.com/docs/nx-os/#!working-with-nx-api-cli
    
    + pyeapi, Arista EOS eAPI and is used to configure Arista EOS devices.
    
    + netaddr, network addresses such as IPv4, IPv6, and layer 2 addresses (MAC addresses). 

    https://github.com/drkjam/netaddr
    
    + ciscoconfparse, A Python library that is able to parse a Cisco IOS-style configuration and returns the output 

    + NSot, a database tracking inventory and metadata,  It provides a frontend GUI based on Python Django. 
    
    https://github.com/dropbox/nsot

    + Nornir, A new automation framework based on Python and consumed directly from Python code without a need to have custom  DSL

    https://github.com/nornir-automation/nornir
    
- system and cloud python libraries 
    + ConfigParser, work with ini 

    https://github.com/python/cpython/blob/master/Lib/configparser.py
    
    + Paramiko, Paramiko is a Python (2.7, 3.4+) implementation of the SSHv2 protocol

    + Pandas, high-performance easy to use data structures and data analysis 
    
    + boto3, official python interface for AWS. https://github.com/boto/boto3
    
    + google-api-pyuthon-client, google official api client https://github.com/google/google-api-python-client

    + pyVmomi, offical vmware python interface https://github.com/vmware/pyvmomi

    + pymysql https://github.com/PyMySQL/PyMySQL
    
    + psycopg, postgresSQL http://initd.org/psycopg/

    + django, high level open source web framework, https://www.djangoproject.com/
    
    + fabric, simple python tool for executing commands and software deployments on remote devices based on SSH 

    https://github.com/fabric/fabric
    
    + SCAPY, a brilliant python based packaet manipulation https://github.com/secdev/scapy
    
    + selenium, a python library used to automate web-browser tasks, https://pypi.org/project/selenium/

- other python package lists, https://github.com/vinta/awesome-python.

-  will use the Excel Read (xlrd) module to read the UC3_devices.xlsx 

- birth of the CiscoConfParse library (https://github.com/mpenning/ciscoconfparse).
, Python and Ansible, later in this book we will automate this process efficiently using the Jinja2 template language (http://jinja.pocoo.org).

$ pip install jinja2 

template file has a .j2 extension at the end. This will make PyCharm recognize the text inside the file as a Jinja2 template 

{% include 'router_day0_template.j2' %}

{% if enabled_ports %}
    {% for port in enabled_ports %}
interface {{ port }}
    no switchport
    no shutdown
    mtu 1520
    duplex auto
    speed auto
    {% endfor %}

{% endif %}

- when you execute the full code, one final thing needs to be done. You need to join the forked process to the main thread/truck, in order to smoothly finish the program's execution

from netmiko import ConnectHandler
from devices import R1, SW1, SW2, SW3, SW4
import multiprocessing as mp
from datetime import datetime

nodes = [R1, SW1, SW2, SW3, SW4]

def connect_to_dev(device):

    net_connect = ConnectHandler(**device)
    output = net_connect.send_command("show run")
    print output

processes = []

start_time = datetime.now()
for device in nodes:
    print("Adding Process to the list")
    processes.append(mp.Process(target=connect_to_dev, args=[device]))

print("Spawning the Process")
for p in processes:
    p.start()

print("Joining the finished process to the main truck")
for p in processes:
    p.join()

end_time = datetime.now()
print("Script Execution tooks {}".format(end_time - start_time))

-  The multiprocessing module has a Queue class that implements a special list, within which a process can insert and consume data.

- head to the CentOS project link (https://www.centos.org/) and click on the Get CentOS Now button

- create linux application with KVM 

- running system administration tasks with Fabric

Fabric (http://www.fabfile.org/) is a high-level Python library that is used to connect to remote servers (through the paramiko library) and execute predefined tasks on them. 

It runs a tool called fab on the machine that hosts the fabric module. This tool will look for a fabfile.py file, located in the same directory that you run the tool in. The fabfile.py file contains your tasks, defined as a Python function that is called from the command line to start the execution on the servers. 

    + install fabric 
    $ pip install fabric 
    
    + operations 
    get(remote_path, local_path), This will download the files from the remote host to the machine running the fabfile
    
    put(local_path, remote_path, use_sudo=False, mirror_local_mode=False, mode=None), This operation will upload the file from the machine running the fabfile (local) to the remote host.
    
    sudo(command, shell=True, pty=True, combine_stderr=True, user=None, quiet=False, warn_only=False, stdout=None, stderr=None, group=None), This operation can be considered another wrapper around the run() command. However, the sudo operation will run the command with the root username by default regardless of the username used to execute the fabfile. 
    
    prompt(text, key=None, default='', validate=None), The user can provide a specific value for the task by using the prompt operation, and the input will be stored inside of a variable and used by tasks.
    
    reboot(wait=120)
    
    + reference check http://docs.fabfile.org/en/1.14/api/core/operations.html. 
    
    + content manager 
source ~/env/bin/activate && pip install wheel
source ~/env/bin/activate && pip install -r requirements.txt
source ~/env/bin/activate && python manage.py migrate
    
- KPI, key performance indicators 
    
    +  leveraging the platform module
    
import platform
system = platform.system()
print(system)
    
- Simple Mail Transfer Protocol (SMTP) that is responsible for sending and receiving emails from mail servers
#!/usr/bin/python
__author__ = "Bassim Aly"
__EMAIL__ = "basim.alyy@gmail.com"

import smtplib
imp        ort platform

Data_Sent_in_Email = ""
Header = """From: PythonEnterpriseAutomationBot <basim.alyy@gmail.com>
To: To Administrator <basim.alyy@gmail.com>
Subject: Monitoring System Report
    
fromaddr = 'yyyyyyyyyyy@gmail.com'
toaddrs  = 'basim.alyy@gmail.com'
username = 'yyyyyyyyyyy@gmail.com'
password = 'xxxxxxxxxx'
server = smtplib.SMTP('smtp.gmail.com:587')
server.ehlo()
server.starttls()
server.login(username,password)

server.sendmail(fromaddr, toaddrs, Data_Sent_in_Email)
server.quit()
    
- automation tool Ansible
    
$ ansible all -m copy -a "src=~/id_rsa dest=~/.ssh/id_rsa mode=0600"
    

# Interacting with the database 
- mysql 

$ yum install MySQL-python


# Ansible for system administration 
- install 
$ sudo yum install epel-release
$ sudo yum install Ansible

$ sudo apt-get update
$ sudo apt-get install software-properties-common
$ sudo apt-add-repository ppa:Ansible/Ansible
$ sudo apt-get update

- Ansible ad hoc mode is used when you need to execute simple operations on remote machines
$ Ansible -i hosts all -m ping

- ansible playbook 

|   - hosts: centos-servers
|     remote_user: root
|   
|     tasks:
|       - name: Install openssh
|         yum: pkg=openssh-server state=installed
|   
|       - name: Start the openssh
|         service: name=sshd state=started enabled=yes

This is a simple playbook, with a single play that contains two tasks:

    Install openssh-server.
    Start the sshd service after installation, and make sure that it's available at the boot time.

condition playbook 
|   - hosts: infra
|     remote_user: root
|   
|     tasks:
|       - name: Install openssh
|         yum: pkg=openssh-server state=installed
|         when: Ansible_distribution == "CentOS"
|   
|       - name: Start the openssh
|         service: name=sshd state=started enabled=yes
|         when: Ansible_distribution == "CentOS"


- creating vmware virtual machines

VMware released the first version of the ESXi that could run directly over the commodity off the shelf (COTS) server while converting it to a resource that could be consumed by multiple separate virtual machines. 

- python vmware client, You can access this model and see the actual values for your infrastructure through the Managed Object Browser (MoB) which gives you access to all object details. We will use the official Python bindings from VMware (pyvmomi) to interact with this model and alter the values (or create them) inside the inventory.

$ pip install -U pyvmomi

GitHub (https://github.com/vmware/pyvmomi-community-samples/tree/master/samples).


# Interacting with the OpenStack API


# Using the scapy framework 
- Scapy (https://scapy.net) is one of the powerful Python tools that is used to capture, sniff, analyze, and manipulate network packets.

Scapy has its own Domain-Specific Language (DSL) that enables the user to describe the packet that he wants to build

- install 
$ pip install scapy

$ yum install tcpdump graphviz imagemagick python-gnuplot python-crypto python-pyx -y

for window and os x 
http://scapy.readthedocs.io/en/latest/installation.html#windows
http://scapy.readthedocs.io/en/latest/installation.html#mac-os-x

- it can be used to manipulate TCP/IP packages 

from scapy.layers.inet import *
from pprint import pprint
pkts = PcapReader("/root/ftp_data.pcap") #should be in wireshark-tcpdump format


p_out = []

for pkt in pkts:
    new_pkt = pkt.payload

    try:
        new_pkt[IP].src = "10.10.88.100"
        new_pkt[IP].dst = "10.10.88.1"
        del (new_pkt[IP].chksum)
        del (new_pkt[TCP].chksum)
    except:
        pass

    pprint(new_pkt.show())
    p_out.append(new_pkt)
send(PacketList(p_out), iface="eth0")

- package sniff 
from scapy.all import *
from pprint import pprint

print("Begin capturing all packets from all interfaces. send ctrl+c to terminate and print summary")
pkts = sniff()

pprint(pkts.summary())

the data can be saved as pcap file 


# Build a network scanner with python 
- nmap 
import subprocess
from netaddr import IPNetwork
network = "192.168.1.0/24"
p = subprocess.Popen(["sudo", "nmap", "-sP", network], stdout=subprocess.PIPE)

for line in p.stdout:
    print(line)

- scanning the services 
$ nmap -p 80 www.google.com
C++ Unit Testing Fundamentals Using Catch=Dror Helper;Note=Erxin

# Introducing Catch 
- Course introduction 
- introducing unit test 
a method (code)

test specific functionality 

clear pass/fail criteria 

runs in isolation, we allowed the test failed only by test logic not any other environment or database link issue 

- simple unit test 

TEST_CLASS(MyUnitTest)
{
    public: 
        TEST_METHOD(TestMethod)
        {
                //your test code 
        }
}

- why write automated test? 
quick feedback, find bug quickly without waiting 

avoid stupid bugs 

- introducing catch, https://github.com/philsquared/catch 

c++ automated cases in headers

no external dependencies 

test names are free-form strings 

powerful "assertions"

excellent error messages 

sections! 

- get started with catch 
    + download catch.cpp 
    
    + define macro 
    #define CATCH_CONFIG_MAIN
    #include "catch.cpp"
    
    TEST_CASE("this is a test name")
    {
        ....
    }
    
- demo 
    + how to get catch 
    
    + write a empty unit test 
    
    #define CATCH_CONFIG_MAIN
    #include "Catch.h"
    
    TEST_CASE("This is a test name", "[TAG]")
    {
        MyClass myClass 
        
        REQUIRE(myClass.MeaningOfLite () == 42);
    }
    
- writing test using catch, T9 predictive text algorithm 

    + unit test t9 algorithm 
    used in older cell phones 
    
    input a sequence of digits 
    
    output suggested words 
    
    + example 
    843 -> "the"
    4663 -> "good"
    43556 -> "hello"
    
- demo writing unit tests using catch 
...

- comparing catch to traditional unit test frameworks. using xUnit test frameworks 
//xUnit require the test method to be a valid variable name 
TEST_METHOD(PassDigitsForHelloReturnCorretString)
{
    ...
        
    //several methods 
    Assert::AreEqual(expected, accepted);
}

//failure message is not intuitive 
    

# Organizing your tests using catch 
- naming your tests 
tests names in catch 

decalred using TEST_CASE

understand what the test does 

execute a subset of your tests 

find the test you need 

failures, root cause analysis 

- avoid at all costs 
"test 1_11_37"

"customer test simple"

"workitem1234"

"workload error exception"
- write good  unit test 
    + express a specific requirement/behavior 
    + should include 
        * the starting state 
        * given input 
        * expected result 
        * unless irrelevant 
    + should be easily found 
    + should not include test 
    
    + example 
    if age > 18 isAdult return tree 
    
    when called with xyz then return true 
    
    should throw exception when invalid user 
    
    given authenticated when invalid number used then transaction will fail 
    
    called with empty list -> return null pointer 
    
- executing catch from command line 
catch & the command line, catch tests are compiled into a console app(exe), use arguments to specify which test(s) to run T9Predict 

test name related arguments 

    + run specific test thisTest
    + run group of tests, customer* 
    + run all test except 
    exclude:otherTest 
    ~otherTest 
    ~*other* 
    
    + combine example 
    a* ~ab* abc 
    run all test start with a, don't run start with ab and run specific test abc 
    
- executing catch from the command line 
    + go the output directory of the project 
    
    + run the compiled test app(exe)
    
    + list test by 
    $ *exe --list-test-names-only 

    find test 
    $ *exe Find* 
    
    test group of test 
    $ *exe "*group name*"
    
- adding tags to your tests 
a simple way to group tests 

additional strings associated with test case 

tag names are not case sensitive 

TEST_CASE("test is a test name", "[tag1][tag2]...")
{

}

    + use tags to categorize tests 
    by code under test(db, model, customer)
    by test type(unit, integration, scenario)
    by execution speed(slow, fast)
    ...
    
    + run test by 
    $ *.exe "[tag-name]"
    $ *.exe ~[tag-name]
    $ *.exe "[A][B]", test both have A and B 
    $ *.exe "[A],[B]", use command means test have A or B
- catch's special tags 
[!hide] or [.], skip/ignore test 
[.][integration] ->[.integration]

[!throws] execlude if run catch with -e or --nothrow 
[!shouldfail] reverse failing logic(pass if fail)
[!mayfail] does not fail the test if assertion fails 
[#<filename>] use -# to specifc filename as tag 

- demo use tags 
    + list all tags 
    $ *.exe -t 
    
    + run a specific tag of tests 
    $ *.exe [tag-name]
    
    + *.exe -l [tag-name-pattern]
    list all the matched test nmes 
    
    + use - and # to  get a list of existings tags and filename together 
    $ exe -t -# 
    
    + use a list of tags for a specific test file 
    $ *.exe -l -# [#file-name]
- creating tag aliases 
    + create a short of tag rule 
    CATCH_REGISTER_TAG-ALIAS("[@abc]", "[a], [b]~[c]")
    
    then [@abc] stand for [a], [b]~[c]
    
- more command line arguments 
get help by -h, -?, --help 
define a list of test by a file, -f, --input file <filename> 
output redirection, -o, --out <filename> 
visual studio and xcode support -b, --break when test fail 
get a full report by -a, --abort, make sure the test stop on the first error 
use -x, --aboutx to specify a number of failures when the test abort 
- summary 
    
    
# Asserting using catch 
- module overview 
- why you should care about test failure 
REQUIRE, single macro for all/most assertions needs 

write the assertion in plain code 

excellent failure messages 

    + understand why the test wrong 
    
    + reduce debugging time 
    
    + purpose of the test 
- is it okay to use multiple assertions in one test?

have a implies a single assertion for one unit test, which not force a single assertion which means one unity test should only for test one case 

the problem with multiple asssertions 

testing more than one aspect 

- using require and check 
CHECK works like REQUIRE. CHECK let test finish but fail after it's done 

REQUIRE_FALSE 
CHECK_FALSE 
these two are used for check false result 

- how to handle multiple assertions in one test 
    + split to multiple test 
    + use CHECK 
    + override operator == 
    + compare collections 
    + use multiple asserts 
- handling mutliple assertions in one test 
- asserting for exceptions 
REQUIRE_THROWS(expression)
CHECK_THROWS(expression)

for test for exception 

REQUIRE_THROWS_AS(expression, type)
CHECK_THROWS_AS(expression, type)

REQUIRE_NOTHROW(expression)
CHECK_NOTHROW(expression)
- demo asserting for exceptions 
- adding more information using logging macros 
INFO, only report when test failure 
WARN, always show 
FAIL, always show 
CAPTURE, equal to INFO 

INFO(string-message)

- using string conversions, if the type could not be convert to string then the error message will not display the right value. there are four ways to show the message 
    + operator << 
    + Catch::toString 
    + Catch::StringMaker specialisation 
    + CATCH_TRANSLATE_EXCEPTION 

    + c++ standard way to write a conversion 
    ostream& operator<< (ostream& os, MyType const& value)
    {
        os << convert (value);
        return os;
    }
    
    when you can't change the production code by overload the Catch::toString method 
    namespace Catch 
    {
        string toString(MyType const& value)
        {
            return convert (value);
        }
    }
    
    overloading toString doesn't work you could use 
    namespace Catch
    {
        template<> struct StringMaker<T> 
        {
            static std::string convert(T const& value)
            {
                return convert(value);
            }
        }
    }
    
    //this is used for define custom exception or message which are not std error 
    CATCH_TRANSLATE_EXCEPTION(MyType& ex)
    {
        return ex.message(); 
    }
- summary 
    
    
# Handling Duplicate Code 
- Module Overview 
- Code duplication in unit and integration tests 
    + unit test 
    focused 
    isolated 
    fast 

    + integration tests
    depends on environment 
    extensive 
    usually slower 
    
    + reference course, out side in unit test on pluralsight 
    
    + duplication in unit tests 
        * integration test subject 
        * common operations 
        * duplication in integration tests 
        creation environment 
        common operations 
        clean up 
        
- Dry vs DAMP 
    + don't repeat yourself 
    avoid duplication 
    increases maintainability 
    isolate change 
    
    + damp, descriptive and meaningful phrases 
    promote code readability 
    reduce the time it takes to read and understand the code 

    + personally DAMP > DRY 
    in unit tests 
    
- Using test fixtures 
Test suite, exe/dll 
fixture, class 
test case, method 

    + creating test fixtures, fixture classs's constructor is called when the test start and the destructor is called after the test finished 
    class MyFixture {
        MyFixture() 
        {
        }
        
        ~MyFixture(){
        }
        
        protected:
            void helperMethod(){}
    }
    
    TEST_CASE_METHOD(MyFixture, "test1")
    {
        helperMethod();//the method of the fixture could be called directly inside the test
    }
    
    + reduce code duplication 
    preconditions 
    cleanup after each test 
    provide common operation 
    common state/environment 
    
    + group code in logical units 
    group related tests 
    use inheritance for utility code 
    
    + hide unintresting code 
    
    + the methods 
- Demo: using test fixture 
- The problems of using test fixture, when the test logic become huge 
    + hard to read and understand 
    + difficult to fix failures 
    + hides some of the test's logic 
    + setup/teardown for all tests 
    + increased complexity, violate SRP, shared logic between tests 
    
    + when should use test fixtures 
        * integration tests 
        * create hierarchy 
        * Catch is a much better way which called section 
- using sections 
    + introducing sections 
    each section is a fork in which the code runs as a separate test but following the common parts before or with the common parts after that specific section 
    
    TEST_CASE('this is a test case")
    {
        SECTION("test section 1")
        {
        
        }
        
        SECTION("test section 2")
        {
        
        }
    }
    
    + benefits of using sections 
    each section executed independently 
    
    enable resuse only for the test you want to group together 
    
    easy to read and maintain than fixture, it should read from top to bottom 
    
    supports nested sections 
    
    break of one section will not fail other sections 
- Demo using sections 
- Introducing BDD 
"the deeper i got into tdd, the more i felf that my own journey had been less of a wax-on, wax-off process of gradual mastery than a series of blind alleys..."

"i decied it must be possible to present tdd in a way that gets straight to the good stuff and avoids all the pitfalls" 

Dan North introducing BDD 

    + reference causes 
    Navigating the xDD alphabet soup https://youtu.be/c6xgP5mEdN8
    
    + BDD 
    user story -> scenario1 -> Given 
                                                 When 
                                                 Then 
                           scenario2 -> ...
                           
    use Gherkin syntax                 

    + behavior driven development 
    use tests to describe behavior of the system 
    
    given when then 
    
    create  executable specification 
    
    does specification can be write by non developer 
    
    clear confusion 
- Writing BDD secnarios using catch, Catch support a bunch of different macros for BDD 

SCENARIO("first rol is strike", "[Strick][Bowling]")
{
    GIVEN("blowed strike on first run")
    {
        Game game;
        game.roll(10);
    }
    
    WHEN("all rest rolls are gutter balls")
    {
        RollSeveral(game, 18, 0);
        THEN("total score is 10")
        {
            REQUIRE(game.Score() == 10);
        }
    }
    
    WHEN("...")...
}
    + when the test fails the descriptions of each step will be displayed such as 
    Scenario:...
    Given: ...
    When: ...
    Then:....
    
    the detail of the error message relative to the implementation 
    
- Demo writing BDD scenarios using catch 
- summary 
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    